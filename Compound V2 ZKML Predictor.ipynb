{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b95d07f-0b8e-4741-a2ce-42117e2ccb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# Load the CSV files\n",
    "X_df = pd.read_csv('X_tensor_Compound_V2.csv')\n",
    "y_df = pd.read_csv('y_tensor_Compound_V2.csv')\n",
    "\n",
    "# Convert DataFrames to tensors\n",
    "X_tensor = torch.tensor(X_df.values, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y_df.values.squeeze(), dtype=torch.float32)  # Assuming y is 1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e05e075c-a6f6-4616-b4ae-6de6449c4ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Predator\\AppData\\Roaming\\Python\\Python311\\site-packages\\prefect\\tasks.py:332: UserWarning: A task named 'Generate Prediction' and defined at 'C:\\Users\\Predator\\AppData\\Roaming\\Python\\Python311\\site-packages\\giza_actions\\task.py:10' conflicts with another task. Consider specifying a unique `name` parameter in the task definition:\n",
      "\n",
      " `@task(name='my_unique_name', ...)`\n",
      "  warnings.warn(\n",
      "C:\\Users\\Predator\\AppData\\Roaming\\Python\\Python311\\site-packages\\prefect\\flows.py:336: UserWarning: A flow named 'Execute Prediction Process' and defined at 'C:\\Users\\Predator\\AppData\\Roaming\\Python\\Python311\\site-packages\\giza_actions\\action.py:25' conflicts with another flow. Consider specifying a unique `name` parameter in the flow definition:\n",
      "\n",
      " `@flow(name='my_unique_name', ...)`\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">10:10:23.772 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Created flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'crazy-unicorn'</span> for flow<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> 'Execute Prediction Process'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "10:10:23.772 | \u001b[36mINFO\u001b[0m    | Created flow run\u001b[35m 'crazy-unicorn'\u001b[0m for flow\u001b[1;35m 'Execute Prediction Process'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">10:10:23.776 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Action run 'crazy-unicorn' - View at <span style=\"color: #0000ff; text-decoration-color: #0000ff\">https://actions-server-williamskie123-dblzzhtf5q-ew.a.run.app/flow-runs/flow-run/32bf3a5e-6bf5-43c7-99ac-81eeae4f83cf</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "10:10:23.776 | \u001b[36mINFO\u001b[0m    | Action run 'crazy-unicorn' - View at \u001b[94mhttps://actions-server-williamskie123-dblzzhtf5q-ew.a.run.app/flow-runs/flow-run/32bf3a5e-6bf5-43c7-99ac-81eeae4f83cf\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">10:10:26.585 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Action run 'crazy-unicorn' - Created task run 'Generate Prediction-0' for task 'Generate Prediction'\n",
       "</pre>\n"
      ],
      "text/plain": [
       "10:10:26.585 | \u001b[36mINFO\u001b[0m    | Action run 'crazy-unicorn' - Created task run 'Generate Prediction-0' for task 'Generate Prediction'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">10:10:26.591 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Action run 'crazy-unicorn' - Executing 'Generate Prediction-0' immediately...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "10:10:26.591 | \u001b[36mINFO\u001b[0m    | Action run 'crazy-unicorn' - Executing 'Generate Prediction-0' immediately...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Starting deserialization process...\n",
      "âœ… Deserialization completed! ðŸŽ‰\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">10:10:40.976 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Generate Prediction-0' - [[-0.01408386]]\n",
       "</pre>\n"
      ],
      "text/plain": [
       "10:10:40.976 | \u001b[36mINFO\u001b[0m    | Task run 'Generate Prediction-0' - [[-0.01408386]]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">10:10:40.980 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Generate Prediction-0' - 602cee55b94e4c8096019f8e0d31f7fe\n",
       "</pre>\n"
      ],
      "text/plain": [
       "10:10:40.980 | \u001b[36mINFO\u001b[0m    | Task run 'Generate Prediction-0' - 602cee55b94e4c8096019f8e0d31f7fe\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">10:10:41.360 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Generate Prediction-0' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "10:10:41.360 | \u001b[36mINFO\u001b[0m    | Task run 'Generate Prediction-0' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">10:10:41.711 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Action run 'crazy-unicorn' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "10:10:41.711 | \u001b[36mINFO\u001b[0m    | Action run 'crazy-unicorn' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "from giza_actions.model import GizaModel\n",
    "from giza_actions.action import Action, action\n",
    "from giza_actions.task import task\n",
    "\n",
    "model_identifier = 368  # Customize with the specific model ID\n",
    "version_identifier = 11  # Customize with the specific version ID\n",
    "\n",
    "@task(name='Generate Prediction')\n",
    "def predict_output(data_for_prediction, model_id, version_id):\n",
    "    # Initialize the prediction model with the given model and version IDs.\n",
    "    prediction_model = GizaModel(id=model_id, version=version_id)\n",
    "    \n",
    "    # Perform prediction using the model's predict method and ensure output integrity.\n",
    "    prediction_result, prediction_tracking_id = prediction_model.predict(\n",
    "        input_feed={\"model_input\": data_for_prediction}, \n",
    "        verifiable=True,\n",
    "        job_size=\"XL\",\n",
    "    )\n",
    "    print(prediction_result)\n",
    "    print(prediction_tracking_id)\n",
    "    return prediction_result, prediction_tracking_id\n",
    "\n",
    "@action(name='Execute Prediction Process', log_prints=True)\n",
    "def execute_prediction():\n",
    "    single_test_sample = X_tensor.numpy().astype(\"float32\")[1].reshape(1,-1)\n",
    "    # Using a single sample from the test set for making a prediction\n",
    "    prediction_result, operation_tracking_id = predict_output(single_test_sample, model_identifier, version_identifier) \n",
    "    return prediction_result, operation_tracking_id\n",
    "\n",
    "prediction_result, proof_id = execute_prediction()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
